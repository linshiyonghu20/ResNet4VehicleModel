{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Technologies\n",
    "# CUDA toolkit 10.0\n",
    "# Tensorflow-gpu 2.0\n",
    "# cuDNN 7.6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "from PIL import Image, ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VirtualDeviceConfiguration(memory_limit=6040)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6040)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img nummber:  16185\n",
      "label number:  196\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgPath</th>\n",
       "      <th>label</th>\n",
       "      <th>testTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16175</th>\n",
       "      <td>car_ims/016176.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16176</th>\n",
       "      <td>car_ims/016177.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16177</th>\n",
       "      <td>car_ims/016178.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16178</th>\n",
       "      <td>car_ims/016179.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16179</th>\n",
       "      <td>car_ims/016180.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16180</th>\n",
       "      <td>car_ims/016181.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16181</th>\n",
       "      <td>car_ims/016182.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16182</th>\n",
       "      <td>car_ims/016183.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16183</th>\n",
       "      <td>car_ims/016184.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16184</th>\n",
       "      <td>car_ims/016185.jpg</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  imgPath                          label  testTag\n",
       "16175  car_ims/016176.jpg  smart fortwo Convertible 2012        1\n",
       "16176  car_ims/016177.jpg  smart fortwo Convertible 2012        1\n",
       "16177  car_ims/016178.jpg  smart fortwo Convertible 2012        1\n",
       "16178  car_ims/016179.jpg  smart fortwo Convertible 2012        1\n",
       "16179  car_ims/016180.jpg  smart fortwo Convertible 2012        1\n",
       "16180  car_ims/016181.jpg  smart fortwo Convertible 2012        1\n",
       "16181  car_ims/016182.jpg  smart fortwo Convertible 2012        1\n",
       "16182  car_ims/016183.jpg  smart fortwo Convertible 2012        1\n",
       "16183  car_ims/016184.jpg  smart fortwo Convertible 2012        1\n",
       "16184  car_ims/016185.jpg  smart fortwo Convertible 2012        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map betweem image names and labels \n",
    "matData = loadmat('./cars_annos.mat')\n",
    "\n",
    "labelsList = []\n",
    "for arr in matData['annotations'][0]:\n",
    "    imgPath = arr[0][0]\n",
    "    labelNum = arr[5][0][0]\n",
    "    splitTag = arr[6][0][0]\n",
    "    labelsList.append([imgPath, labelNum, splitTag])\n",
    "print(\"img nummber: \", len(labelsList))\n",
    "\n",
    "labelNameDict = {}\n",
    "labelList = []\n",
    "for i,arr in enumerate(matData['class_names'][0]):\n",
    "    labelName = arr[0]\n",
    "    labelNameDict[i+1] = labelName\n",
    "    labelList.append(labelName)\n",
    "print(\"label number: \", len(labelNameDict))\n",
    "\n",
    "labelsDF = pd.DataFrame(labelsList, columns=['imgPath', 'label', 'testTag'])\n",
    "labelsDF['label'] = labelsDF['label'].map(labelNameDict)\n",
    "labelsDF.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of train set: 8144\n",
      "amount of test set: 8041\n",
      "amount of validationDF: 1000\n"
     ]
    }
   ],
   "source": [
    "#split train and test\n",
    "trainDF = labelsDF[labelsDF['testTag']==0]\n",
    "print(\"amount of train set:\", len(trainDF))\n",
    "testDF = labelsDF[labelsDF['testTag']==1]\n",
    "print(\"amount of test set:\", len(testDF))\n",
    "validationDF = testDF.sample(n=1000)\n",
    "print(\"amount of validationDF:\", len(validationDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parms\n",
    "classNum = len(labelNameDict)\n",
    "classContent = labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " model = tf.keras.models.load_model('models-res152/part-train-2/car.17-0.26.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#base model\\nbase_model = tf.keras.applications.resnet.ResNet152(weights='resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#base model\n",
    "base_model = tf.keras.applications.resnet.ResNet152(weights='resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntop = base_model.output\\ntop = tf.keras.layers.GlobalAveragePooling2D()(top)\\ntop = tf.keras.layers.Flatten()(top)\\ntop = tf.keras.layers.Dense(2048, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(top)\\ntop = tf.keras.layers.BatchNormalization()(top)\\ntop = tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(top)\\ntop = tf.keras.layers.BatchNormalization(name='bn_fc_01')(top)\\ntop_model = tf.keras.layers.Dense(classNum, activation='softmax')(top)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "top = base_model.output\n",
    "top = tf.keras.layers.GlobalAveragePooling2D()(top)\n",
    "top = tf.keras.layers.Flatten()(top)\n",
    "top = tf.keras.layers.Dense(2048, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(top)\n",
    "top = tf.keras.layers.BatchNormalization()(top)\n",
    "top = tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(top)\n",
    "top = tf.keras.layers.BatchNormalization(name='bn_fc_01')(top)\n",
    "top_model = tf.keras.layers.Dense(classNum, activation='softmax')(top)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = tf.keras.models.Model(inputs=base_model.input, outputs=top_model)\\nfor layer in base_model.layers[:130]:\\n    layer.trainable = False\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=top_model)\n",
    "for layer in base_model.layers[:130]:\n",
    "    layer.trainable = False\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call back functions\n",
    "early_stop = tf.keras.callbacks.EarlyStopping('loss', patience=5)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('./models-res152/car.{epoch:02d}-{val_acc:.2f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau('loss', factor=0.1, patience=1)\n",
    "callbacks = [early_stop, model_checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocess parms\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 5\n",
    "epochs = 100\n",
    "trainNum = len(trainDF)\n",
    "validNum = len(validationDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 validated image filenames belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "#input data preprocess\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    trainDF,\n",
    "    target_size = (img_width, img_height),\n",
    "    x_col = 'imgPath',\n",
    "    y_col = 'label',\n",
    "    classes = classContent,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 validated image filenames belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "#valid data preprocess\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    validationDF,\n",
    "    target_size = (img_width, img_height),\n",
    "    x_col = 'imgPath',\n",
    "    y_col = 'label',\n",
    "    classes = classContent,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 2.5012 - acc: 0.3443\n",
      "Epoch 00001: val_acc improved from -inf to 0.07200, saving model to ./models-res152/car.01-0.07.hdf5\n",
      "1629/1629 [==============================] - 1135s 697ms/step - loss: 2.5012 - acc: 0.3442 - val_loss: 9.5270 - val_acc: 0.0720\n",
      "Epoch 2/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 2.4360 - acc: 0.3568\n",
      "Epoch 00002: val_acc improved from 0.07200 to 0.22900, saving model to ./models-res152/car.02-0.23.hdf5\n",
      "1629/1629 [==============================] - 1125s 691ms/step - loss: 2.4368 - acc: 0.3568 - val_loss: 3.4277 - val_acc: 0.2290\n",
      "Epoch 3/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 2.3977 - acc: 0.3612\n",
      "Epoch 00003: val_acc did not improve from 0.22900\n",
      "1629/1629 [==============================] - 1113s 683ms/step - loss: 2.3996 - acc: 0.3611 - val_loss: 5.3264 - val_acc: 0.1340\n",
      "Epoch 4/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 2.3170 - acc: 0.3751\n",
      "Epoch 00004: val_acc did not improve from 0.22900\n",
      "1629/1629 [==============================] - 1115s 684ms/step - loss: 2.3171 - acc: 0.3751 - val_loss: 5.4362 - val_acc: 0.1290\n",
      "Epoch 5/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 2.3125 - acc: 0.3849\n",
      "Epoch 00005: val_acc did not improve from 0.22900\n",
      "1629/1629 [==============================] - 1118s 686ms/step - loss: 2.3121 - acc: 0.3848 - val_loss: 10.0737 - val_acc: 0.0430\n",
      "Epoch 6/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 2.2447 - acc: 0.4023\n",
      "Epoch 00006: val_acc did not improve from 0.22900\n",
      "1629/1629 [==============================] - 1113s 684ms/step - loss: 2.2445 - acc: 0.4023 - val_loss: 4.1008 - val_acc: 0.2030\n",
      "Epoch 7/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 2.1681 - acc: 0.4134\n",
      "Epoch 00007: val_acc improved from 0.22900 to 0.25100, saving model to ./models-res152/car.07-0.25.hdf5\n",
      "1629/1629 [==============================] - 1118s 686ms/step - loss: 2.1681 - acc: 0.4133 - val_loss: 3.4857 - val_acc: 0.2510\n",
      "Epoch 8/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 2.1395 - acc: 0.4247\n",
      "Epoch 00008: val_acc did not improve from 0.25100\n",
      "1629/1629 [==============================] - 1112s 683ms/step - loss: 2.1389 - acc: 0.4250 - val_loss: 4.5469 - val_acc: 0.1750\n",
      "Epoch 9/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 2.0746 - acc: 0.4423\n",
      "Epoch 00009: val_acc did not improve from 0.25100\n",
      "1629/1629 [==============================] - 1119s 687ms/step - loss: 2.0741 - acc: 0.4425 - val_loss: 4.2801 - val_acc: 0.1970\n",
      "Epoch 10/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 2.0801 - acc: 0.4395\n",
      "Epoch 00010: val_acc improved from 0.25100 to 0.33500, saving model to ./models-res152/car.10-0.34.hdf5\n",
      "1629/1629 [==============================] - 1118s 686ms/step - loss: 2.0796 - acc: 0.4396 - val_loss: 2.7199 - val_acc: 0.3350\n",
      "Epoch 11/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.7659 - acc: 0.5168\n",
      "Epoch 00011: val_acc improved from 0.33500 to 0.39200, saving model to ./models-res152/car.11-0.39.hdf5\n",
      "1629/1629 [==============================] - 1123s 689ms/step - loss: 1.7656 - acc: 0.5167 - val_loss: 2.6990 - val_acc: 0.3920\n",
      "Epoch 12/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.6588 - acc: 0.5416\n",
      "Epoch 00012: val_acc improved from 0.39200 to 0.39300, saving model to ./models-res152/car.12-0.39.hdf5\n",
      "1629/1629 [==============================] - 1118s 686ms/step - loss: 1.6584 - acc: 0.5416 - val_loss: 2.5330 - val_acc: 0.3930\n",
      "Epoch 13/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.5744 - acc: 0.5681\n",
      "Epoch 00013: val_acc did not improve from 0.39300\n",
      "1629/1629 [==============================] - 1109s 681ms/step - loss: 1.5743 - acc: 0.5681 - val_loss: 2.6960 - val_acc: 0.3660\n",
      "Epoch 14/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.5643 - acc: 0.5667\n",
      "Epoch 00014: val_acc did not improve from 0.39300\n",
      "1629/1629 [==============================] - 1117s 686ms/step - loss: 1.5644 - acc: 0.5664 - val_loss: 2.6159 - val_acc: 0.3840\n",
      "Epoch 15/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.5440 - acc: 0.5703\n",
      "Epoch 00015: val_acc improved from 0.39300 to 0.40900, saving model to ./models-res152/car.15-0.41.hdf5\n",
      "1629/1629 [==============================] - 1125s 690ms/step - loss: 1.5438 - acc: 0.5704 - val_loss: 2.5112 - val_acc: 0.4090\n",
      "Epoch 16/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.5040 - acc: 0.5718\n",
      "Epoch 00016: val_acc improved from 0.40900 to 0.41200, saving model to ./models-res152/car.16-0.41.hdf5\n",
      "1629/1629 [==============================] - 1123s 689ms/step - loss: 1.5048 - acc: 0.5716 - val_loss: 2.5487 - val_acc: 0.4120\n",
      "Epoch 17/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.4995 - acc: 0.5789\n",
      "Epoch 00017: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1112s 683ms/step - loss: 1.4991 - acc: 0.5791 - val_loss: 2.6273 - val_acc: 0.4030\n",
      "Epoch 18/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.4605 - acc: 0.5898\n",
      "Epoch 00018: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1110s 681ms/step - loss: 1.4605 - acc: 0.5899 - val_loss: 2.7898 - val_acc: 0.3920\n",
      "Epoch 19/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.4159 - acc: 0.6002\n",
      "Epoch 00019: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1110s 681ms/step - loss: 1.4158 - acc: 0.6002 - val_loss: 2.7668 - val_acc: 0.4030\n",
      "Epoch 20/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.4356 - acc: 0.6011\n",
      "Epoch 00020: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1113s 683ms/step - loss: 1.4359 - acc: 0.6011 - val_loss: 2.8067 - val_acc: 0.3870\n",
      "Epoch 21/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3855 - acc: 0.6035\n",
      "Epoch 00021: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1125s 691ms/step - loss: 1.3858 - acc: 0.6034 - val_loss: 2.8413 - val_acc: 0.3990\n",
      "Epoch 22/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.4003 - acc: 0.6055\n",
      "Epoch 00022: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1127s 692ms/step - loss: 1.3999 - acc: 0.6056 - val_loss: 2.9174 - val_acc: 0.3910\n",
      "Epoch 23/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3625 - acc: 0.6129\n",
      "Epoch 00023: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1121s 688ms/step - loss: 1.3624 - acc: 0.6128 - val_loss: 2.8820 - val_acc: 0.3970\n",
      "Epoch 24/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3867 - acc: 0.6044\n",
      "Epoch 00024: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1111s 682ms/step - loss: 1.3875 - acc: 0.6042 - val_loss: 2.9039 - val_acc: 0.3960\n",
      "Epoch 25/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3589 - acc: 0.6144\n",
      "Epoch 00025: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1116s 685ms/step - loss: 1.3586 - acc: 0.6144 - val_loss: 2.8852 - val_acc: 0.4010\n",
      "Epoch 26/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3464 - acc: 0.6192\n",
      "Epoch 00026: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1116s 685ms/step - loss: 1.3472 - acc: 0.6191 - val_loss: 3.0043 - val_acc: 0.3880\n",
      "Epoch 27/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3795 - acc: 0.6168\n",
      "Epoch 00027: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1109s 681ms/step - loss: 1.3797 - acc: 0.6165 - val_loss: 2.8075 - val_acc: 0.3950\n",
      "Epoch 28/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3257 - acc: 0.6201\n",
      "Epoch 00028: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1112s 683ms/step - loss: 1.3253 - acc: 0.6202 - val_loss: 2.8323 - val_acc: 0.4010\n",
      "Epoch 29/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3416 - acc: 0.6180\n",
      "Epoch 00029: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1110s 681ms/step - loss: 1.3413 - acc: 0.6181 - val_loss: 2.7790 - val_acc: 0.4010\n",
      "Epoch 30/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3808 - acc: 0.6098\n",
      "Epoch 00030: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1115s 685ms/step - loss: 1.3805 - acc: 0.6099 - val_loss: 2.8386 - val_acc: 0.3980\n",
      "Epoch 31/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3814 - acc: 0.6070\n",
      "Epoch 00031: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1114s 684ms/step - loss: 1.3813 - acc: 0.6068 - val_loss: 2.9226 - val_acc: 0.3950\n",
      "Epoch 32/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3236 - acc: 0.6267\n",
      "Epoch 00032: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1110s 681ms/step - loss: 1.3234 - acc: 0.6268 - val_loss: 2.8990 - val_acc: 0.3930\n",
      "Epoch 33/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3671 - acc: 0.6074\n",
      "Epoch 00033: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1112s 683ms/step - loss: 1.3669 - acc: 0.6074 - val_loss: 2.7966 - val_acc: 0.3990\n",
      "Epoch 34/100\n",
      "1628/1629 [============================>.] - ETA: 0s - loss: 1.3602 - acc: 0.6202\n",
      "Epoch 00034: val_acc did not improve from 0.41200\n",
      "1629/1629 [==============================] - 1109s 681ms/step - loss: 1.3612 - acc: 0.6198 - val_loss: 2.9309 - val_acc: 0.3920\n",
      "Epoch 35/100\n",
      "1509/1629 [==========================>...] - ETA: 1:18 - loss: 1.3866 - acc: 0.6086"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-40cece893da2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m               training=training))\n\u001b[0m\u001b[0;32m    253\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    799\u001b[0m                                      \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m                                      \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m                                      self.epsilon)\n\u001b[0m\u001b[0;32m    802\u001b[0m     \u001b[1;31m# If some components of the shape got lost due to adjustments, fix that.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[1;34m(x, mean, variance, offset, scale, variance_epsilon, name)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[1;31m# Note: tensorflow/contrib/quantize/python/fold_batch_norms.py depends on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[1;31m# the precise order of ops that are generated by the expression below.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m     return x * math_ops.cast(inv, x.dtype) + math_ops.cast(\n\u001b[0m\u001b[0;32m   1442\u001b[0m         offset - mean * inv if offset is not None else -mean * inv, x.dtype)\n\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1204\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6683\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   6684\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mul\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6685\u001b[1;33m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[0;32m   6686\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6687\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train model\n",
    "model_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = ceil(trainNum / batch_size),\n",
    "    validation_data = valid_generator,\n",
    "    validation_steps = ceil(validNum / batch_size),\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
